<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>TensorFlow 2 - Quickstart for Beginners</title>
  <meta name="author" content="Salerno" />
  
  
  
  
  <meta name="keywords" content="devows, hugo, go">
  
  
  <meta name="description" content="Site template made by devcows using hugo">

  <meta name="generator" content="Hugo 0.61.0" />

  
  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.11.2/css/all.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="/css/animate.css" rel="stylesheet">

  
  
    <link href="/css/style.green.css" rel="stylesheet" id="theme-stylesheet">
  

  
  <link href="/css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png" />

  
  <link href="/css/owl.carousel.css" rel="stylesheet">
  <link href="/css/owl.theme.css" rel="stylesheet">

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="DFS">

  
  
  
  
  
  
  
  <meta property="og:locale" content="en_us">
  <meta property="og:site_name" content="DFS">
  <meta property="og:title" content="TensorFlow 2 - Quickstart for Beginners">
  <meta property="og:type" content="article">
  <meta property="og:url" content="/blog/2020/03/14/2020-03-14-tensorflow-2-quickstart-for-beginners/" />
  <meta property="og:description" content="Site template made by devcows using hugo">
  <meta property="og:image" content="/img/banners/python.png">
  <meta property="og:image:type" content="image/png">
  
  
  
    <meta property="og:image:width" content="1024">
    <meta property="og:image:height" content="512">
  
  
  <meta property="og:updated_time" content="2020-03-14T00:00:00Z">
  
    
    
    <meta property="article:section" content="TensorFlow">
    
    
    <meta property="article:published_time" content="2020-03-14T00:00:00Z">
    <meta property="article:modified_time" content="2020-03-14T00:00:00Z">
  

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@GoHugoIO">
  <meta name="twitter:title" content="TensorFlow 2 - Quickstart for Beginners">
  
  <meta name="twitter:image" content="/img/banners/python.png">
  
  <meta name="twitter:description" content="Site template made by devcows using hugo">
  

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="/">
                    <img src="/img/logo.png" alt="TensorFlow 2 - Quickstart for Beginners logo" class="logo hidden-xs hidden-sm">
                    
                    <span class="sr-only">TensorFlow 2 - Quickstart for Beginners - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fas fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  
                  <li class="dropdown active">
                    
                    <a href="/blog/">Blog</a>
                    
                  </li>
                  
                  
                  <li class="dropdown">
                    
                    <a href="/contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>TensorFlow 2 - Quickstart for Beginners</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        
                          <p class="text-muted text-uppercase mb-small text-right">
                            By <a href="#">Salerno</a>
                             | 
                            March 14, 2020
                          </p>
                        

                        <div id="post-content">
                          


<pre class="python"><code>
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
</code></pre>
<pre class="python"><code>
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0</code></pre>
<pre class="python"><code>
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation=&#39;relu&#39;),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])</code></pre>
<pre class="python"><code>
predictions = model(x_train[:1]).numpy()</code></pre>
<pre><code>## WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer&#39;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&#39;s dtype defaults to floatx.
## 
## If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.
## 
## To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&#39;float64&#39;)`. To change just this layer, pass dtype=&#39;float64&#39; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.</code></pre>
<pre class="python"><code>predictions</code></pre>
<pre><code>## array([[-0.05698846, -0.41724604,  0.20074931, -0.89817846, -0.434907  ,
##          0.28240982, -0.03079729,  0.32150513,  0.17321926,  0.46897537]],
##       dtype=float32)</code></pre>
<pre class="python"><code>
tf.nn.softmax(predictions).numpy()</code></pre>
<pre><code>## array([[0.0913271 , 0.06370035, 0.11817721, 0.03937998, 0.06258521,
##         0.12823261, 0.09375067, 0.13334519, 0.11496817, 0.15453358]],
##       dtype=float32)</code></pre>
<pre class="python"><code>
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)</code></pre>
<pre class="python"><code>
loss_fn(y_train[:1], predictions).numpy()</code></pre>
<pre><code>## 2.0539095</code></pre>
<pre class="python"><code>
model.compile(optimizer=&#39;adam&#39;,
              loss=loss_fn,
              metrics=[&#39;accuracy&#39;])</code></pre>
<pre class="python"><code>
model.fit(x_train, y_train, epochs=5)</code></pre>
<pre><code>## Train on 60000 samples
## Epoch 1/5
## 
##    32/60000 [..............................] - ETA: 9:27 - loss: 2.4178 - accuracy: 0.0625
##   800/60000 [..............................] - ETA: 26s - loss: 1.7418 - accuracy: 0.4487 
##  1632/60000 [..............................] - ETA: 14s - loss: 1.3067 - accuracy: 0.6127
##  2432/60000 [&gt;.............................] - ETA: 10s - loss: 1.1040 - accuracy: 0.6785
##  3232/60000 [&gt;.............................] - ETA: 8s - loss: 0.9713 - accuracy: 0.7231 
##  4032/60000 [=&gt;............................] - ETA: 7s - loss: 0.8779 - accuracy: 0.7520
##  4832/60000 [=&gt;............................] - ETA: 6s - loss: 0.8049 - accuracy: 0.7715
##  5536/60000 [=&gt;............................] - ETA: 6s - loss: 0.7582 - accuracy: 0.7840
##  5984/60000 [=&gt;............................] - ETA: 6s - loss: 0.7327 - accuracy: 0.7898
##  6240/60000 [==&gt;...........................] - ETA: 6s - loss: 0.7179 - accuracy: 0.7939
##  6464/60000 [==&gt;...........................] - ETA: 6s - loss: 0.7075 - accuracy: 0.7970
##  7008/60000 [==&gt;...........................] - ETA: 6s - loss: 0.6859 - accuracy: 0.8028
##  7776/60000 [==&gt;...........................] - ETA: 6s - loss: 0.6622 - accuracy: 0.8090
##  8608/60000 [===&gt;..........................] - ETA: 5s - loss: 0.6318 - accuracy: 0.8189
##  9440/60000 [===&gt;..........................] - ETA: 5s - loss: 0.6086 - accuracy: 0.8261
## 10144/60000 [====&gt;.........................] - ETA: 5s - loss: 0.5909 - accuracy: 0.8310
## 10944/60000 [====&gt;.........................] - ETA: 5s - loss: 0.5725 - accuracy: 0.8353
## 11744/60000 [====&gt;.........................] - ETA: 4s - loss: 0.5554 - accuracy: 0.8406
## 12512/60000 [=====&gt;........................] - ETA: 4s - loss: 0.5443 - accuracy: 0.8433
## 13344/60000 [=====&gt;........................] - ETA: 4s - loss: 0.5312 - accuracy: 0.8461
## 14144/60000 [======&gt;.......................] - ETA: 4s - loss: 0.5194 - accuracy: 0.8491
## 14880/60000 [======&gt;.......................] - ETA: 4s - loss: 0.5109 - accuracy: 0.8512
## 15680/60000 [======&gt;.......................] - ETA: 4s - loss: 0.5011 - accuracy: 0.8543
## 16448/60000 [=======&gt;......................] - ETA: 3s - loss: 0.4901 - accuracy: 0.8576
## 17216/60000 [=======&gt;......................] - ETA: 3s - loss: 0.4817 - accuracy: 0.8600
## 17952/60000 [=======&gt;......................] - ETA: 3s - loss: 0.4738 - accuracy: 0.8621
## 18656/60000 [========&gt;.....................] - ETA: 3s - loss: 0.4660 - accuracy: 0.8648
## 19232/60000 [========&gt;.....................] - ETA: 3s - loss: 0.4589 - accuracy: 0.8670
## 19936/60000 [========&gt;.....................] - ETA: 3s - loss: 0.4516 - accuracy: 0.8694
## 20608/60000 [=========&gt;....................] - ETA: 3s - loss: 0.4479 - accuracy: 0.8708
## 21088/60000 [=========&gt;....................] - ETA: 3s - loss: 0.4444 - accuracy: 0.8715
## 21344/60000 [=========&gt;....................] - ETA: 3s - loss: 0.4417 - accuracy: 0.8724
## 21760/60000 [=========&gt;....................] - ETA: 3s - loss: 0.4389 - accuracy: 0.8732
## 22144/60000 [==========&gt;...................] - ETA: 3s - loss: 0.4355 - accuracy: 0.8743
## 22656/60000 [==========&gt;...................] - ETA: 3s - loss: 0.4313 - accuracy: 0.8755
## 23488/60000 [==========&gt;...................] - ETA: 3s - loss: 0.4254 - accuracy: 0.8778
## 24288/60000 [===========&gt;..................] - ETA: 3s - loss: 0.4202 - accuracy: 0.8789
## 25088/60000 [===========&gt;..................] - ETA: 3s - loss: 0.4150 - accuracy: 0.8804
## 25888/60000 [===========&gt;..................] - ETA: 2s - loss: 0.4087 - accuracy: 0.8822
## 26720/60000 [============&gt;.................] - ETA: 2s - loss: 0.4047 - accuracy: 0.8833
## 27520/60000 [============&gt;.................] - ETA: 2s - loss: 0.4008 - accuracy: 0.8849
## 28320/60000 [=============&gt;................] - ETA: 2s - loss: 0.3954 - accuracy: 0.8866
## 29120/60000 [=============&gt;................] - ETA: 2s - loss: 0.3909 - accuracy: 0.8878
## 29920/60000 [=============&gt;................] - ETA: 2s - loss: 0.3870 - accuracy: 0.8884
## 30720/60000 [==============&gt;...............] - ETA: 2s - loss: 0.3827 - accuracy: 0.8897
## 31456/60000 [==============&gt;...............] - ETA: 2s - loss: 0.3793 - accuracy: 0.8905
## 32128/60000 [===============&gt;..............] - ETA: 2s - loss: 0.3768 - accuracy: 0.8912
## 32960/60000 [===============&gt;..............] - ETA: 2s - loss: 0.3737 - accuracy: 0.8920
## 33792/60000 [===============&gt;..............] - ETA: 2s - loss: 0.3699 - accuracy: 0.8932
## 34592/60000 [================&gt;.............] - ETA: 2s - loss: 0.3673 - accuracy: 0.8939
## 35392/60000 [================&gt;.............] - ETA: 2s - loss: 0.3635 - accuracy: 0.8949
## 36192/60000 [=================&gt;............] - ETA: 1s - loss: 0.3612 - accuracy: 0.8957
## 37024/60000 [=================&gt;............] - ETA: 1s - loss: 0.3574 - accuracy: 0.8969
## 37344/60000 [=================&gt;............] - ETA: 1s - loss: 0.3566 - accuracy: 0.8972
## 37632/60000 [=================&gt;............] - ETA: 1s - loss: 0.3555 - accuracy: 0.8976
## 37888/60000 [=================&gt;............] - ETA: 1s - loss: 0.3544 - accuracy: 0.8978
## 38464/60000 [==================&gt;...........] - ETA: 1s - loss: 0.3519 - accuracy: 0.8984
## 39232/60000 [==================&gt;...........] - ETA: 1s - loss: 0.3499 - accuracy: 0.8991
## 40000/60000 [===================&gt;..........] - ETA: 1s - loss: 0.3466 - accuracy: 0.8998
## 40800/60000 [===================&gt;..........] - ETA: 1s - loss: 0.3437 - accuracy: 0.9006
## 41632/60000 [===================&gt;..........] - ETA: 1s - loss: 0.3418 - accuracy: 0.9013
## 42336/60000 [====================&gt;.........] - ETA: 1s - loss: 0.3397 - accuracy: 0.9020
## 43008/60000 [====================&gt;.........] - ETA: 1s - loss: 0.3376 - accuracy: 0.9025
## 43648/60000 [====================&gt;.........] - ETA: 1s - loss: 0.3361 - accuracy: 0.9028
## 44352/60000 [=====================&gt;........] - ETA: 1s - loss: 0.3339 - accuracy: 0.9034
## 45056/60000 [=====================&gt;........] - ETA: 1s - loss: 0.3324 - accuracy: 0.9036
## 45664/60000 [=====================&gt;........] - ETA: 1s - loss: 0.3306 - accuracy: 0.9042
## 46432/60000 [======================&gt;.......] - ETA: 1s - loss: 0.3281 - accuracy: 0.9050
## 47264/60000 [======================&gt;.......] - ETA: 1s - loss: 0.3265 - accuracy: 0.9054
## 48032/60000 [=======================&gt;......] - ETA: 0s - loss: 0.3252 - accuracy: 0.9059
## 48832/60000 [=======================&gt;......] - ETA: 0s - loss: 0.3225 - accuracy: 0.9065
## 49664/60000 [=======================&gt;......] - ETA: 0s - loss: 0.3203 - accuracy: 0.9072
## 50464/60000 [========================&gt;.....] - ETA: 0s - loss: 0.3187 - accuracy: 0.9077
## 51104/60000 [========================&gt;.....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9081
## 51904/60000 [========================&gt;.....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9088
## 52352/60000 [=========================&gt;....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9088
## 52512/60000 [=========================&gt;....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9090
## 52928/60000 [=========================&gt;....] - ETA: 0s - loss: 0.3123 - accuracy: 0.9093
## 53344/60000 [=========================&gt;....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9097
## 54080/60000 [==========================&gt;...] - ETA: 0s - loss: 0.3093 - accuracy: 0.9103
## 54816/60000 [==========================&gt;...] - ETA: 0s - loss: 0.3076 - accuracy: 0.9108
## 55520/60000 [==========================&gt;...] - ETA: 0s - loss: 0.3063 - accuracy: 0.9111
## 56256/60000 [===========================&gt;..] - ETA: 0s - loss: 0.3045 - accuracy: 0.9117
## 57056/60000 [===========================&gt;..] - ETA: 0s - loss: 0.3026 - accuracy: 0.9122
## 57856/60000 [===========================&gt;..] - ETA: 0s - loss: 0.3007 - accuracy: 0.9129
## 58560/60000 [============================&gt;.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9134
## 59392/60000 [============================&gt;.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9139
## 60000/60000 [==============================] - 5s 80us/sample - loss: 0.2963 - accuracy: 0.9142
## Epoch 2/5
## 
##    32/60000 [..............................] - ETA: 3s - loss: 0.2624 - accuracy: 0.9375
##   832/60000 [..............................] - ETA: 3s - loss: 0.1807 - accuracy: 0.9483
##  1536/60000 [..............................] - ETA: 4s - loss: 0.1674 - accuracy: 0.9525
##  2336/60000 [&gt;.............................] - ETA: 3s - loss: 0.1721 - accuracy: 0.9512
##  3168/60000 [&gt;.............................] - ETA: 3s - loss: 0.1665 - accuracy: 0.9530
##  3936/60000 [&gt;.............................] - ETA: 3s - loss: 0.1615 - accuracy: 0.9545
##  4672/60000 [=&gt;............................] - ETA: 3s - loss: 0.1616 - accuracy: 0.9544
##  5504/60000 [=&gt;............................] - ETA: 3s - loss: 0.1575 - accuracy: 0.9557
##  6304/60000 [==&gt;...........................] - ETA: 3s - loss: 0.1587 - accuracy: 0.9546
##  7040/60000 [==&gt;...........................] - ETA: 3s - loss: 0.1589 - accuracy: 0.9544
##  7840/60000 [==&gt;...........................] - ETA: 3s - loss: 0.1592 - accuracy: 0.9533
##  8288/60000 [===&gt;..........................] - ETA: 3s - loss: 0.1568 - accuracy: 0.9538
##  8448/60000 [===&gt;..........................] - ETA: 3s - loss: 0.1572 - accuracy: 0.9536
##  8608/60000 [===&gt;..........................] - ETA: 4s - loss: 0.1557 - accuracy: 0.9539
##  9056/60000 [===&gt;..........................] - ETA: 4s - loss: 0.1551 - accuracy: 0.9540
##  9792/60000 [===&gt;..........................] - ETA: 4s - loss: 0.1571 - accuracy: 0.9527
## 10528/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1563 - accuracy: 0.9529
## 11200/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1548 - accuracy: 0.9533
## 11936/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1562 - accuracy: 0.9529
## 12672/60000 [=====&gt;........................] - ETA: 3s - loss: 0.1559 - accuracy: 0.9528
## 13408/60000 [=====&gt;........................] - ETA: 3s - loss: 0.1539 - accuracy: 0.9534
## 14080/60000 [======&gt;.......................] - ETA: 3s - loss: 0.1526 - accuracy: 0.9537
## 14784/60000 [======&gt;.......................] - ETA: 3s - loss: 0.1528 - accuracy: 0.9537
## 15424/60000 [======&gt;.......................] - ETA: 3s - loss: 0.1515 - accuracy: 0.9544
## 16096/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1504 - accuracy: 0.9547
## 16672/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1495 - accuracy: 0.9549
## 17408/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1519 - accuracy: 0.9543
## 18176/60000 [========&gt;.....................] - ETA: 3s - loss: 0.1528 - accuracy: 0.9543
## 18912/60000 [========&gt;.....................] - ETA: 3s - loss: 0.1531 - accuracy: 0.9541
## 19648/60000 [========&gt;.....................] - ETA: 3s - loss: 0.1520 - accuracy: 0.9544
## 20480/60000 [=========&gt;....................] - ETA: 3s - loss: 0.1505 - accuracy: 0.9550
## 21312/60000 [=========&gt;....................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9550
## 22144/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1501 - accuracy: 0.9548
## 22848/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9549
## 23104/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9549
## 23520/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9549
## 23936/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1504 - accuracy: 0.9547
## 24608/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1504 - accuracy: 0.9548
## 25376/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9552
## 26080/60000 [============&gt;.................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9551
## 26784/60000 [============&gt;.................] - ETA: 2s - loss: 0.1493 - accuracy: 0.9550
## 27488/60000 [============&gt;.................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9551
## 28128/60000 [=============&gt;................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9551
## 28800/60000 [=============&gt;................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9550
## 29440/60000 [=============&gt;................] - ETA: 2s - loss: 0.1497 - accuracy: 0.9554
## 30208/60000 [==============&gt;...............] - ETA: 2s - loss: 0.1489 - accuracy: 0.9557
## 31008/60000 [==============&gt;...............] - ETA: 2s - loss: 0.1492 - accuracy: 0.9555
## 31712/60000 [==============&gt;...............] - ETA: 2s - loss: 0.1489 - accuracy: 0.9555
## 32544/60000 [===============&gt;..............] - ETA: 2s - loss: 0.1483 - accuracy: 0.9557
## 33376/60000 [===============&gt;..............] - ETA: 2s - loss: 0.1479 - accuracy: 0.9556
## 34144/60000 [================&gt;.............] - ETA: 1s - loss: 0.1478 - accuracy: 0.9556
## 34880/60000 [================&gt;.............] - ETA: 1s - loss: 0.1477 - accuracy: 0.9558
## 35712/60000 [================&gt;.............] - ETA: 1s - loss: 0.1476 - accuracy: 0.9558
## 36512/60000 [=================&gt;............] - ETA: 1s - loss: 0.1467 - accuracy: 0.9562
## 37312/60000 [=================&gt;............] - ETA: 1s - loss: 0.1456 - accuracy: 0.9565
## 38080/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1455 - accuracy: 0.9567
## 38368/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1453 - accuracy: 0.9568
## 38784/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1448 - accuracy: 0.9570
## 39264/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1451 - accuracy: 0.9569
## 40032/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1455 - accuracy: 0.9564
## 40832/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1455 - accuracy: 0.9563
## 41632/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1446 - accuracy: 0.9567
## 42432/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1441 - accuracy: 0.9570
## 43136/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1433 - accuracy: 0.9572
## 43936/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1425 - accuracy: 0.9575
## 44768/60000 [=====================&gt;........] - ETA: 1s - loss: 0.1421 - accuracy: 0.9576
## 45536/60000 [=====================&gt;........] - ETA: 1s - loss: 0.1417 - accuracy: 0.9577
## 46336/60000 [======================&gt;.......] - ETA: 1s - loss: 0.1415 - accuracy: 0.9577
## 47168/60000 [======================&gt;.......] - ETA: 0s - loss: 0.1421 - accuracy: 0.9573
## 47968/60000 [======================&gt;.......] - ETA: 0s - loss: 0.1425 - accuracy: 0.9574
## 48736/60000 [=======================&gt;......] - ETA: 0s - loss: 0.1427 - accuracy: 0.9573
## 49536/60000 [=======================&gt;......] - ETA: 0s - loss: 0.1424 - accuracy: 0.9573
## 50272/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1425 - accuracy: 0.9573
## 50944/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1424 - accuracy: 0.9573
## 51584/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1427 - accuracy: 0.9572
## 52256/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1428 - accuracy: 0.9571
## 53024/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1426 - accuracy: 0.9572
## 53792/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1425 - accuracy: 0.9572
## 54112/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1424 - accuracy: 0.9572
## 54400/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1423 - accuracy: 0.9572
## 54752/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1424 - accuracy: 0.9571
## 55264/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1424 - accuracy: 0.9572
## 55968/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1423 - accuracy: 0.9571
## 56800/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1419 - accuracy: 0.9573
## 57632/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1414 - accuracy: 0.9574
## 58400/60000 [============================&gt;.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9574
## 59232/60000 [============================&gt;.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9575
## 60000/60000 [==============================] - 5s 76us/sample - loss: 0.1404 - accuracy: 0.9576
## Epoch 3/5
## 
##    32/60000 [..............................] - ETA: 5s - loss: 0.1492 - accuracy: 0.9062
##   864/60000 [..............................] - ETA: 3s - loss: 0.0943 - accuracy: 0.9699
##  1696/60000 [..............................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9623
##  2528/60000 [&gt;.............................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9640
##  3360/60000 [&gt;.............................] - ETA: 3s - loss: 0.1033 - accuracy: 0.9676
##  4160/60000 [=&gt;............................] - ETA: 3s - loss: 0.1012 - accuracy: 0.9683
##  4928/60000 [=&gt;............................] - ETA: 3s - loss: 0.1032 - accuracy: 0.9688
##  5600/60000 [=&gt;............................] - ETA: 3s - loss: 0.1040 - accuracy: 0.9689
##  6432/60000 [==&gt;...........................] - ETA: 3s - loss: 0.1057 - accuracy: 0.9686
##  7264/60000 [==&gt;...........................] - ETA: 3s - loss: 0.1080 - accuracy: 0.9676
##  8096/60000 [===&gt;..........................] - ETA: 3s - loss: 0.1060 - accuracy: 0.9684
##  8800/60000 [===&gt;..........................] - ETA: 3s - loss: 0.1044 - accuracy: 0.9686
##  9600/60000 [===&gt;..........................] - ETA: 3s - loss: 0.1046 - accuracy: 0.9688
## 10048/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1040 - accuracy: 0.9687
## 10272/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1037 - accuracy: 0.9687
## 10464/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1032 - accuracy: 0.9688
## 11040/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1041 - accuracy: 0.9686
## 11680/60000 [====&gt;.........................] - ETA: 3s - loss: 0.1038 - accuracy: 0.9688
## 12416/60000 [=====&gt;........................] - ETA: 3s - loss: 0.1040 - accuracy: 0.9687
## 13152/60000 [=====&gt;........................] - ETA: 3s - loss: 0.1054 - accuracy: 0.9687
## 13888/60000 [=====&gt;........................] - ETA: 3s - loss: 0.1060 - accuracy: 0.9688
## 14656/60000 [======&gt;.......................] - ETA: 3s - loss: 0.1053 - accuracy: 0.9692
## 15392/60000 [======&gt;.......................] - ETA: 3s - loss: 0.1063 - accuracy: 0.9690
## 16224/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1064 - accuracy: 0.9691
## 17024/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1059 - accuracy: 0.9693
## 17664/60000 [=======&gt;......................] - ETA: 3s - loss: 0.1059 - accuracy: 0.9693
## 18240/60000 [========&gt;.....................] - ETA: 3s - loss: 0.1058 - accuracy: 0.9692
## 18976/60000 [========&gt;.....................] - ETA: 3s - loss: 0.1059 - accuracy: 0.9692
## 19776/60000 [========&gt;.....................] - ETA: 2s - loss: 0.1050 - accuracy: 0.9696
## 20544/60000 [=========&gt;....................] - ETA: 2s - loss: 0.1048 - accuracy: 0.9699
## 21216/60000 [=========&gt;....................] - ETA: 2s - loss: 0.1045 - accuracy: 0.9699
## 21984/60000 [=========&gt;....................] - ETA: 2s - loss: 0.1051 - accuracy: 0.9693
## 22816/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1057 - accuracy: 0.9691
## 23584/60000 [==========&gt;...................] - ETA: 2s - loss: 0.1061 - accuracy: 0.9690
## 24320/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1059 - accuracy: 0.9690
## 24992/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1064 - accuracy: 0.9688
## 25216/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1061 - accuracy: 0.9689
## 25632/60000 [===========&gt;..................] - ETA: 2s - loss: 0.1059 - accuracy: 0.9688
## 26048/60000 [============&gt;.................] - ETA: 2s - loss: 0.1064 - accuracy: 0.9688
## 26720/60000 [============&gt;.................] - ETA: 2s - loss: 0.1071 - accuracy: 0.9687
## 27392/60000 [============&gt;.................] - ETA: 2s - loss: 0.1068 - accuracy: 0.9687
## 28128/60000 [=============&gt;................] - ETA: 2s - loss: 0.1062 - accuracy: 0.9688
## 28960/60000 [=============&gt;................] - ETA: 2s - loss: 0.1056 - accuracy: 0.9690
## 29792/60000 [=============&gt;................] - ETA: 2s - loss: 0.1052 - accuracy: 0.9692
## 30624/60000 [==============&gt;...............] - ETA: 2s - loss: 0.1051 - accuracy: 0.9692
## 31296/60000 [==============&gt;...............] - ETA: 2s - loss: 0.1057 - accuracy: 0.9690
## 32096/60000 [===============&gt;..............] - ETA: 2s - loss: 0.1052 - accuracy: 0.9691
## 32928/60000 [===============&gt;..............] - ETA: 2s - loss: 0.1057 - accuracy: 0.9692
## 33760/60000 [===============&gt;..............] - ETA: 1s - loss: 0.1054 - accuracy: 0.9691
## 34496/60000 [================&gt;.............] - ETA: 1s - loss: 0.1057 - accuracy: 0.9688
## 35232/60000 [================&gt;.............] - ETA: 1s - loss: 0.1058 - accuracy: 0.9688
## 36064/60000 [=================&gt;............] - ETA: 1s - loss: 0.1056 - accuracy: 0.9689
## 36864/60000 [=================&gt;............] - ETA: 1s - loss: 0.1058 - accuracy: 0.9686
## 37568/60000 [=================&gt;............] - ETA: 1s - loss: 0.1057 - accuracy: 0.9687
## 38336/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1052 - accuracy: 0.9689
## 39168/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1052 - accuracy: 0.9689
## 39840/60000 [==================&gt;...........] - ETA: 1s - loss: 0.1048 - accuracy: 0.9690
## 40576/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1051 - accuracy: 0.9689
## 41024/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1048 - accuracy: 0.9690
## 41184/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1048 - accuracy: 0.9690
## 41632/60000 [===================&gt;..........] - ETA: 1s - loss: 0.1046 - accuracy: 0.9690
## 42080/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1044 - accuracy: 0.9691
## 42880/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1047 - accuracy: 0.9691
## 43712/60000 [====================&gt;.........] - ETA: 1s - loss: 0.1048 - accuracy: 0.9690
## 44416/60000 [=====================&gt;........] - ETA: 1s - loss: 0.1049 - accuracy: 0.9689
## 45216/60000 [=====================&gt;........] - ETA: 1s - loss: 0.1059 - accuracy: 0.9684
## 46048/60000 [======================&gt;.......] - ETA: 1s - loss: 0.1057 - accuracy: 0.9685
## 46880/60000 [======================&gt;.......] - ETA: 0s - loss: 0.1053 - accuracy: 0.9685
## 47648/60000 [======================&gt;.......] - ETA: 0s - loss: 0.1055 - accuracy: 0.9684
## 48448/60000 [=======================&gt;......] - ETA: 0s - loss: 0.1052 - accuracy: 0.9684
## 49280/60000 [=======================&gt;......] - ETA: 0s - loss: 0.1055 - accuracy: 0.9684
## 50144/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1051 - accuracy: 0.9685
## 50784/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1054 - accuracy: 0.9684
## 51488/60000 [========================&gt;.....] - ETA: 0s - loss: 0.1055 - accuracy: 0.9684
## 52224/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1056 - accuracy: 0.9683
## 52928/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1059 - accuracy: 0.9682
## 53696/60000 [=========================&gt;....] - ETA: 0s - loss: 0.1057 - accuracy: 0.9683
## 54528/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1057 - accuracy: 0.9683
## 55328/60000 [==========================&gt;...] - ETA: 0s - loss: 0.1060 - accuracy: 0.9683
## 56160/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1061 - accuracy: 0.9683
## 56960/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1067 - accuracy: 0.9681
## 57248/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1065 - accuracy: 0.9681
## 57664/60000 [===========================&gt;..] - ETA: 0s - loss: 0.1066 - accuracy: 0.9681
## 58112/60000 [============================&gt;.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9681
## 58816/60000 [============================&gt;.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9681
## 59552/60000 [============================&gt;.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9682
## 60000/60000 [==============================] - 4s 75us/sample - loss: 0.1063 - accuracy: 0.9681
## Epoch 4/5
## 
##    32/60000 [..............................] - ETA: 3s - loss: 0.0716 - accuracy: 0.9688
##   768/60000 [..............................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9596
##  1376/60000 [..............................] - ETA: 4s - loss: 0.0958 - accuracy: 0.9651
##  2016/60000 [&gt;.............................] - ETA: 4s - loss: 0.0833 - accuracy: 0.9722
##  2656/60000 [&gt;.............................] - ETA: 4s - loss: 0.0838 - accuracy: 0.9721
##  3264/60000 [&gt;.............................] - ETA: 4s - loss: 0.0877 - accuracy: 0.9706
##  3968/60000 [&gt;.............................] - ETA: 4s - loss: 0.0850 - accuracy: 0.9728
##  4800/60000 [=&gt;............................] - ETA: 4s - loss: 0.0837 - accuracy: 0.9735
##  5600/60000 [=&gt;............................] - ETA: 4s - loss: 0.0878 - accuracy: 0.9720
##  6400/60000 [==&gt;...........................] - ETA: 3s - loss: 0.0881 - accuracy: 0.9722
##  7200/60000 [==&gt;...........................] - ETA: 3s - loss: 0.0885 - accuracy: 0.9719
##  8032/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0848 - accuracy: 0.9731
##  8864/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0843 - accuracy: 0.9731
##  9696/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0833 - accuracy: 0.9739
## 10432/60000 [====&gt;.........................] - ETA: 3s - loss: 0.0820 - accuracy: 0.9743
## 11232/60000 [====&gt;.........................] - ETA: 3s - loss: 0.0814 - accuracy: 0.9746
## 12064/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0812 - accuracy: 0.9748
## 12544/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0829 - accuracy: 0.9740
## 12640/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0831 - accuracy: 0.9740
## 13056/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0831 - accuracy: 0.9739
## 13472/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0839 - accuracy: 0.9736
## 14080/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0852 - accuracy: 0.9731
## 14848/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0853 - accuracy: 0.9729
## 15648/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0852 - accuracy: 0.9730
## 16480/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0851 - accuracy: 0.9728
## 17184/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0858 - accuracy: 0.9726
## 17984/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0858 - accuracy: 0.9725
## 18784/60000 [========&gt;.....................] - ETA: 3s - loss: 0.0855 - accuracy: 0.9726
## 19520/60000 [========&gt;.....................] - ETA: 2s - loss: 0.0861 - accuracy: 0.9726
## 20320/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0866 - accuracy: 0.9722
## 21152/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0858 - accuracy: 0.9724
## 21952/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0851 - accuracy: 0.9727
## 22784/60000 [==========&gt;...................] - ETA: 2s - loss: 0.0858 - accuracy: 0.9727
## 23584/60000 [==========&gt;...................] - ETA: 2s - loss: 0.0853 - accuracy: 0.9729
## 24416/60000 [===========&gt;..................] - ETA: 2s - loss: 0.0855 - accuracy: 0.9728
## 25248/60000 [===========&gt;..................] - ETA: 2s - loss: 0.0849 - accuracy: 0.9732
## 26048/60000 [============&gt;.................] - ETA: 2s - loss: 0.0848 - accuracy: 0.9732
## 26720/60000 [============&gt;.................] - ETA: 2s - loss: 0.0842 - accuracy: 0.9734
## 27488/60000 [============&gt;.................] - ETA: 2s - loss: 0.0847 - accuracy: 0.9730
## 28288/60000 [=============&gt;................] - ETA: 2s - loss: 0.0853 - accuracy: 0.9730
## 28832/60000 [=============&gt;................] - ETA: 2s - loss: 0.0853 - accuracy: 0.9729
## 28992/60000 [=============&gt;................] - ETA: 2s - loss: 0.0855 - accuracy: 0.9729
## 29440/60000 [=============&gt;................] - ETA: 2s - loss: 0.0853 - accuracy: 0.9729
## 29920/60000 [=============&gt;................] - ETA: 2s - loss: 0.0852 - accuracy: 0.9728
## 30560/60000 [==============&gt;...............] - ETA: 2s - loss: 0.0848 - accuracy: 0.9729
## 31360/60000 [==============&gt;...............] - ETA: 2s - loss: 0.0851 - accuracy: 0.9730
## 32192/60000 [===============&gt;..............] - ETA: 2s - loss: 0.0854 - accuracy: 0.9729
## 32928/60000 [===============&gt;..............] - ETA: 1s - loss: 0.0858 - accuracy: 0.9728
## 33760/60000 [===============&gt;..............] - ETA: 1s - loss: 0.0858 - accuracy: 0.9727
## 34528/60000 [================&gt;.............] - ETA: 1s - loss: 0.0859 - accuracy: 0.9727
## 35168/60000 [================&gt;.............] - ETA: 1s - loss: 0.0859 - accuracy: 0.9727
## 35872/60000 [================&gt;.............] - ETA: 1s - loss: 0.0862 - accuracy: 0.9726
## 36608/60000 [=================&gt;............] - ETA: 1s - loss: 0.0863 - accuracy: 0.9727
## 37216/60000 [=================&gt;............] - ETA: 1s - loss: 0.0860 - accuracy: 0.9728
## 37856/60000 [=================&gt;............] - ETA: 1s - loss: 0.0862 - accuracy: 0.9728
## 38496/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0865 - accuracy: 0.9729
## 39136/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0867 - accuracy: 0.9728
## 39904/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0871 - accuracy: 0.9728
## 40640/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0869 - accuracy: 0.9729
## 41280/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0868 - accuracy: 0.9729
## 41952/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0869 - accuracy: 0.9729
## 42592/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0867 - accuracy: 0.9729
## 43104/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0867 - accuracy: 0.9729
## 43232/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0867 - accuracy: 0.9729
## 43616/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0866 - accuracy: 0.9730
## 43776/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0867 - accuracy: 0.9729
## 44192/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0866 - accuracy: 0.9729
## 44480/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0866 - accuracy: 0.9729
## 45152/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0866 - accuracy: 0.9730
## 45792/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0864 - accuracy: 0.9731
## 46400/60000 [======================&gt;.......] - ETA: 1s - loss: 0.0865 - accuracy: 0.9730
## 47072/60000 [======================&gt;.......] - ETA: 1s - loss: 0.0869 - accuracy: 0.9729
## 47776/60000 [======================&gt;.......] - ETA: 0s - loss: 0.0868 - accuracy: 0.9730
## 48448/60000 [=======================&gt;......] - ETA: 0s - loss: 0.0863 - accuracy: 0.9731
## 49120/60000 [=======================&gt;......] - ETA: 0s - loss: 0.0865 - accuracy: 0.9730
## 49824/60000 [=======================&gt;......] - ETA: 0s - loss: 0.0867 - accuracy: 0.9729
## 50432/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0865 - accuracy: 0.9729
## 51072/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0864 - accuracy: 0.9729
## 51840/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0869 - accuracy: 0.9728
## 52576/60000 [=========================&gt;....] - ETA: 0s - loss: 0.0869 - accuracy: 0.9729
## 53408/60000 [=========================&gt;....] - ETA: 0s - loss: 0.0869 - accuracy: 0.9729
## 54208/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0871 - accuracy: 0.9728
## 55008/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0871 - accuracy: 0.9729
## 55712/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0870 - accuracy: 0.9730
## 56512/60000 [===========================&gt;..] - ETA: 0s - loss: 0.0870 - accuracy: 0.9730
## 57344/60000 [===========================&gt;..] - ETA: 0s - loss: 0.0866 - accuracy: 0.9731
## 57952/60000 [===========================&gt;..] - ETA: 0s - loss: 0.0865 - accuracy: 0.9731
## 58368/60000 [============================&gt;.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9731
## 58560/60000 [============================&gt;.] - ETA: 0s - loss: 0.0864 - accuracy: 0.9732
## 58880/60000 [============================&gt;.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9731
## 59552/60000 [============================&gt;.] - ETA: 0s - loss: 0.0867 - accuracy: 0.9732
## 60000/60000 [==============================] - 5s 78us/sample - loss: 0.0867 - accuracy: 0.9732
## Epoch 5/5
## 
##    32/60000 [..............................] - ETA: 5s - loss: 0.0417 - accuracy: 1.0000
##   832/60000 [..............................] - ETA: 3s - loss: 0.0792 - accuracy: 0.9784
##  1632/60000 [..............................] - ETA: 3s - loss: 0.0696 - accuracy: 0.9804
##  2464/60000 [&gt;.............................] - ETA: 3s - loss: 0.0723 - accuracy: 0.9793
##  3168/60000 [&gt;.............................] - ETA: 3s - loss: 0.0709 - accuracy: 0.9792
##  3968/60000 [&gt;.............................] - ETA: 3s - loss: 0.0731 - accuracy: 0.9776
##  4768/60000 [=&gt;............................] - ETA: 3s - loss: 0.0746 - accuracy: 0.9773
##  5568/60000 [=&gt;............................] - ETA: 3s - loss: 0.0725 - accuracy: 0.9784
##  6304/60000 [==&gt;...........................] - ETA: 3s - loss: 0.0717 - accuracy: 0.9786
##  7040/60000 [==&gt;...........................] - ETA: 3s - loss: 0.0752 - accuracy: 0.9778
##  7712/60000 [==&gt;...........................] - ETA: 3s - loss: 0.0736 - accuracy: 0.9780
##  8448/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0722 - accuracy: 0.9787
##  9088/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0717 - accuracy: 0.9790
##  9824/60000 [===&gt;..........................] - ETA: 3s - loss: 0.0724 - accuracy: 0.9790
## 10656/60000 [====&gt;.........................] - ETA: 3s - loss: 0.0724 - accuracy: 0.9789
## 11392/60000 [====&gt;.........................] - ETA: 3s - loss: 0.0727 - accuracy: 0.9787
## 12224/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0716 - accuracy: 0.9788
## 13024/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0713 - accuracy: 0.9791
## 13824/60000 [=====&gt;........................] - ETA: 3s - loss: 0.0719 - accuracy: 0.9789
## 14176/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0719 - accuracy: 0.9788
## 14528/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0713 - accuracy: 0.9790
## 14784/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0724 - accuracy: 0.9790
## 15392/60000 [======&gt;.......................] - ETA: 3s - loss: 0.0733 - accuracy: 0.9785
## 16032/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0735 - accuracy: 0.9783
## 16800/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0748 - accuracy: 0.9777
## 17600/60000 [=======&gt;......................] - ETA: 3s - loss: 0.0751 - accuracy: 0.9774
## 18368/60000 [========&gt;.....................] - ETA: 3s - loss: 0.0752 - accuracy: 0.9775
## 19040/60000 [========&gt;.....................] - ETA: 3s - loss: 0.0751 - accuracy: 0.9773
## 19712/60000 [========&gt;.....................] - ETA: 2s - loss: 0.0753 - accuracy: 0.9772
## 20416/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0749 - accuracy: 0.9773
## 21184/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0741 - accuracy: 0.9775
## 21824/60000 [=========&gt;....................] - ETA: 2s - loss: 0.0741 - accuracy: 0.9775
## 22624/60000 [==========&gt;...................] - ETA: 2s - loss: 0.0741 - accuracy: 0.9774
## 23232/60000 [==========&gt;...................] - ETA: 2s - loss: 0.0740 - accuracy: 0.9774
## 23936/60000 [==========&gt;...................] - ETA: 2s - loss: 0.0734 - accuracy: 0.9776
## 24736/60000 [===========&gt;..................] - ETA: 2s - loss: 0.0732 - accuracy: 0.9776
## 25536/60000 [===========&gt;..................] - ETA: 2s - loss: 0.0729 - accuracy: 0.9775
## 26368/60000 [============&gt;.................] - ETA: 2s - loss: 0.0724 - accuracy: 0.9777
## 27168/60000 [============&gt;.................] - ETA: 2s - loss: 0.0726 - accuracy: 0.9776
## 27968/60000 [============&gt;.................] - ETA: 2s - loss: 0.0722 - accuracy: 0.9777
## 28704/60000 [=============&gt;................] - ETA: 2s - loss: 0.0720 - accuracy: 0.9777
## 29248/60000 [=============&gt;................] - ETA: 2s - loss: 0.0716 - accuracy: 0.9777
## 29440/60000 [=============&gt;................] - ETA: 2s - loss: 0.0715 - accuracy: 0.9777
## 29600/60000 [=============&gt;................] - ETA: 2s - loss: 0.0715 - accuracy: 0.9777
## 29888/60000 [=============&gt;................] - ETA: 2s - loss: 0.0716 - accuracy: 0.9777
## 30464/60000 [==============&gt;...............] - ETA: 2s - loss: 0.0712 - accuracy: 0.9779
## 31232/60000 [==============&gt;...............] - ETA: 2s - loss: 0.0707 - accuracy: 0.9779
## 32000/60000 [===============&gt;..............] - ETA: 2s - loss: 0.0711 - accuracy: 0.9779
## 32800/60000 [===============&gt;..............] - ETA: 2s - loss: 0.0712 - accuracy: 0.9776
## 33600/60000 [===============&gt;..............] - ETA: 1s - loss: 0.0707 - accuracy: 0.9778
## 34272/60000 [================&gt;.............] - ETA: 1s - loss: 0.0706 - accuracy: 0.9779
## 35072/60000 [================&gt;.............] - ETA: 1s - loss: 0.0706 - accuracy: 0.9778
## 35872/60000 [================&gt;.............] - ETA: 1s - loss: 0.0710 - accuracy: 0.9778
## 36608/60000 [=================&gt;............] - ETA: 1s - loss: 0.0713 - accuracy: 0.9777
## 37376/60000 [=================&gt;............] - ETA: 1s - loss: 0.0716 - accuracy: 0.9775
## 38176/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0717 - accuracy: 0.9774
## 38976/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0712 - accuracy: 0.9776
## 39712/60000 [==================&gt;...........] - ETA: 1s - loss: 0.0712 - accuracy: 0.9775
## 40416/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0720 - accuracy: 0.9773
## 41088/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0722 - accuracy: 0.9773
## 41760/60000 [===================&gt;..........] - ETA: 1s - loss: 0.0727 - accuracy: 0.9772
## 42432/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0724 - accuracy: 0.9773
## 42976/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0720 - accuracy: 0.9775
## 43744/60000 [====================&gt;.........] - ETA: 1s - loss: 0.0717 - accuracy: 0.9775
## 44192/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0715 - accuracy: 0.9775
## 44416/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0718 - accuracy: 0.9775
## 44544/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0720 - accuracy: 0.9775
## 44960/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0717 - accuracy: 0.9775
## 45632/60000 [=====================&gt;........] - ETA: 1s - loss: 0.0715 - accuracy: 0.9776
## 46368/60000 [======================&gt;.......] - ETA: 1s - loss: 0.0714 - accuracy: 0.9776
## 47072/60000 [======================&gt;.......] - ETA: 0s - loss: 0.0717 - accuracy: 0.9776
## 47840/60000 [======================&gt;.......] - ETA: 0s - loss: 0.0715 - accuracy: 0.9777
## 48640/60000 [=======================&gt;......] - ETA: 0s - loss: 0.0714 - accuracy: 0.9778
## 49408/60000 [=======================&gt;......] - ETA: 0s - loss: 0.0714 - accuracy: 0.9778
## 50208/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0715 - accuracy: 0.9778
## 51008/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0716 - accuracy: 0.9777
## 51808/60000 [========================&gt;.....] - ETA: 0s - loss: 0.0713 - accuracy: 0.9779
## 52608/60000 [=========================&gt;....] - ETA: 0s - loss: 0.0715 - accuracy: 0.9777
## 53440/60000 [=========================&gt;....] - ETA: 0s - loss: 0.0717 - accuracy: 0.9776
## 54240/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0716 - accuracy: 0.9776
## 55040/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0717 - accuracy: 0.9776
## 55712/60000 [==========================&gt;...] - ETA: 0s - loss: 0.0718 - accuracy: 0.9775
## 56480/60000 [===========================&gt;..] - ETA: 0s - loss: 0.0719 - accuracy: 0.9775
## 57216/60000 [===========================&gt;..] - ETA: 0s - loss: 0.0719 - accuracy: 0.9776
## 58016/60000 [============================&gt;.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9776
## 58752/60000 [============================&gt;.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9776
## 59392/60000 [============================&gt;.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9775
## 59616/60000 [============================&gt;.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9775
## 59936/60000 [============================&gt;.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9775
## 60000/60000 [==============================] - 5s 76us/sample - loss: 0.0722 - accuracy: 0.9775
## &lt;tensorflow.python.keras.callbacks.History object at 0x0000000030FCB648&gt;</code></pre>
<pre class="python"><code>
model.evaluate(x_test,  y_test, verbose=2)</code></pre>
<pre><code>## 10000/10000 - 0s - loss: 0.0785 - accuracy: 0.9758
## [0.07854731764825992, 0.9758]</code></pre>
<pre class="python"><code>
probability_model = tf.keras.Sequential([
  model,
  tf.keras.layers.Softmax()
])</code></pre>
<pre class="python"><code>
probability_model(x_test[:5])</code></pre>
<pre><code>## &lt;tf.Tensor: shape=(5, 10), dtype=float32, numpy=
## array([[2.3535537e-07, 1.1087331e-07, 9.0353415e-06, 5.1420293e-04,
##         1.9881577e-10, 7.3825049e-07, 2.8934629e-11, 9.9946576e-01,
##         5.2530334e-07, 9.4558809e-06],
##        [2.3817480e-08, 1.7185285e-04, 9.9982351e-01, 4.2813531e-06,
##         5.3177487e-15, 1.2208089e-07, 2.7580992e-07, 2.4556867e-14,
##         3.9813731e-08, 8.9392667e-11],
##        [5.8469413e-07, 9.9976522e-01, 6.9694550e-05, 1.2077020e-06,
##         2.1383299e-05, 3.3641725e-06, 5.9426807e-06, 9.1478352e-05,
##         4.0556668e-05, 6.5415355e-07],
##        [9.9980491e-01, 4.8268034e-10, 1.4671631e-04, 2.2860399e-07,
##         3.0996057e-07, 6.2423592e-06, 2.7276790e-05, 1.4985205e-06,
##         2.2984095e-08, 1.2802517e-05],
##        [2.9165078e-05, 3.0166632e-08, 6.4240016e-06, 5.6741047e-08,
##         9.9607170e-01, 1.0497470e-06, 1.4562958e-06, 9.0088892e-05,
##         3.5669891e-07, 3.7996941e-03]], dtype=float32)&gt;</code></pre>

                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "andresalerno" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            
            <li>
                <a href="/categories/algorithm">algorithm (2)</a>
            </li>
            
            <li>
                <a href="/categories/binary-search">binary-search (1)</a>
            </li>
            
            <li>
                <a href="/categories/classification">classification (5)</a>
            </li>
            
            <li>
                <a href="/categories/data-frame">data-frame (2)</a>
            </li>
            
            <li>
                <a href="/categories/data-science">data-science (6)</a>
            </li>
            
            <li>
                <a href="/categories/deploying-model">deploying-model (1)</a>
            </li>
            
            <li>
                <a href="/categories/docker">docker (1)</a>
            </li>
            
            <li>
                <a href="/categories/logistic-regression">logistic-regression (2)</a>
            </li>
            
            <li>
                <a href="/categories/lorem">lorem (1)</a>
            </li>
            
            <li>
                <a href="/categories/machine-learning">machine-learning (5)</a>
            </li>
            
            <li>
                <a href="/categories/microsoft-azure">microsoft-azure (1)</a>
            </li>
            
            <li>
                <a href="/categories/ml">ml (2)</a>
            </li>
            
            <li>
                <a href="/categories/models">models (6)</a>
            </li>
            
            <li>
                <a href="/categories/plumber">plumber (1)</a>
            </li>
            
            <li>
                <a href="/categories/programming">programming (13)</a>
            </li>
            
            <li>
                <a href="/categories/pseudo">pseudo (1)</a>
            </li>
            
            <li>
                <a href="/categories/python">python (11)</a>
            </li>
            
            <li>
                <a href="/categories/r">r (5)</a>
            </li>
            
            <li>
                <a href="/categories/r-programming">r-programming (7)</a>
            </li>
            
            <li>
                <a href="/categories/scikit-learn">scikit-learn (1)</a>
            </li>
            
            <li>
                <a href="/categories/starting">starting (1)</a>
            </li>
            
            <li>
                <a href="/categories/tensorflow">tensorflow (2)</a>
            </li>
            
        </ul>
    </div>

</div>








<div class="panel sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            
            <li>
                <a href="/tags/algorithm"><i class="fas fa-tags"></i> algorithm</a>
            </li>
            
            <li>
                <a href="/tags/api"><i class="fas fa-tags"></i> api</a>
            </li>
            
            <li>
                <a href="/tags/classification"><i class="fas fa-tags"></i> classification</a>
            </li>
            
            <li>
                <a href="/tags/data-frame"><i class="fas fa-tags"></i> data-frame</a>
            </li>
            
            <li>
                <a href="/tags/exponential-smoothing"><i class="fas fa-tags"></i> exponential-smoothing</a>
            </li>
            
            <li>
                <a href="/tags/game"><i class="fas fa-tags"></i> game</a>
            </li>
            
            <li>
                <a href="/tags/go"><i class="fas fa-tags"></i> go</a>
            </li>
            
            <li>
                <a href="/tags/golang"><i class="fas fa-tags"></i> golang</a>
            </li>
            
            <li>
                <a href="/tags/hugo"><i class="fas fa-tags"></i> hugo</a>
            </li>
            
            <li>
                <a href="/tags/ipsum"><i class="fas fa-tags"></i> ipsum</a>
            </li>
            
            <li>
                <a href="/tags/keras"><i class="fas fa-tags"></i> keras</a>
            </li>
            
            <li>
                <a href="/tags/knn"><i class="fas fa-tags"></i> knn</a>
            </li>
            
            <li>
                <a href="/tags/linear-regression"><i class="fas fa-tags"></i> linear-regression</a>
            </li>
            
            <li>
                <a href="/tags/logistic-regression"><i class="fas fa-tags"></i> logistic-regression</a>
            </li>
            
            <li>
                <a href="/tags/modeling"><i class="fas fa-tags"></i> modeling</a>
            </li>
            
            <li>
                <a href="/tags/models"><i class="fas fa-tags"></i> models</a>
            </li>
            
            <li>
                <a href="/tags/pca"><i class="fas fa-tags"></i> pca</a>
            </li>
            
            <li>
                <a href="/tags/plot"><i class="fas fa-tags"></i> plot</a>
            </li>
            
            <li>
                <a href="/tags/programming"><i class="fas fa-tags"></i> programming</a>
            </li>
            
            <li>
                <a href="/tags/python"><i class="fas fa-tags"></i> python</a>
            </li>
            
            <li>
                <a href="/tags/r-markdown"><i class="fas fa-tags"></i> r-markdown</a>
            </li>
            
            <li>
                <a href="/tags/r-programming"><i class="fas fa-tags"></i> r-programming</a>
            </li>
            
            <li>
                <a href="/tags/random-forest"><i class="fas fa-tags"></i> random-forest</a>
            </li>
            
            <li>
                <a href="/tags/regression"><i class="fas fa-tags"></i> regression</a>
            </li>
            
            <li>
                <a href="/tags/regression-tree"><i class="fas fa-tags"></i> regression-tree</a>
            </li>
            
            <li>
                <a href="/tags/statistic"><i class="fas fa-tags"></i> statistic</a>
            </li>
            
            <li>
                <a href="/tags/theme"><i class="fas fa-tags"></i> theme</a>
            </li>
            
            <li>
                <a href="/tags/web-service"><i class="fas fa-tags"></i> web-service</a>
            </li>
            
        </ul>
    </div>

</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            <p>A Data Fintech Solutions is a company that has in her DNA the use the most consistent tech and financial tools associated with the most recent tech solutions.</p>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2020/08/19/2020-08-19-supervised-learning-in-r-classification/">
                          
                            <img src="/img/banners/banner-5.png" class="img-responsive" alt="Supervised Learning in R: Classification">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2020/08/19/2020-08-19-supervised-learning-in-r-classification/">Supervised Learning in R: Classification</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2020/04/22/2020-04-22-deploying-r-model/">
                          
                            <img src="/img/banners/banner-5.png" class="img-responsive" alt="Deploying R Model as API Web Service using Docker and Microsoft Azure">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2020/04/22/2020-04-22-deploying-r-model/">Deploying R Model as API Web Service using Docker and Microsoft Azure</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="/blog/2020/03/26/2020-03-26-credit-card-fraud-detection/">
                          
                            <img src="/img/banners/banner-5.png" class="img-responsive" alt="Credit Card Fraud Detection">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="/blog/2020/03/26/2020-03-26-credit-card-fraud-detection/">Credit Card Fraud Detection</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <p class="text-uppercase"><strong>Data Fintech Solutions</strong>
        <br>
        <br>So Jos dos Campos
        <br>
        <strong>Parayba Valley</strong>
      </p>
      

            <a href="/contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright  2019 - 2020  Data Fintech Solutions - All Rights Reserved.</p>
            
            <p class="pull-right">
              Template by <a href="https://bootstrapious.com/p/universal-business-e-commerce-template">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>.
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-154740345-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?key=AIzaSyAIUDnabrE-98Y_3EWdNun6iNBED38BsV0&v=3.exp"></script>

<script src="/js/hpneo.gmaps.js"></script>
<script src="/js/gmaps.init.js"></script>
<script src="/js/front.js"></script>


<script src="/js/owl.carousel.min.js"></script>



  </body>
</html>
