<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on DFS</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on DFS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deploying R Model as API Web Service using Docker and Microsoft Azure</title>
      <link>/blog/2020/04/22/2020-04-22-deploying-r-model/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/04/22/2020-04-22-deploying-r-model/</guid>
      <description>ObjectiveOur goal here is to create a R Model and put-in into production by deploying it as web service API using Docker to containerize (encapsulate) it and Microsoft Azure to host it.
R ModelTo create the model, we going to use mtcars dataset which oneâ€™s is present inside R.
head(mtcars)## mpg cyl disp hp drat wt qsec vs am gear carb## Mazda RX4 21.0 6 160 110 3.</description>
    </item>
    
    <item>
      <title>Credit Card Fraud Detection</title>
      <link>/blog/2020/03/26/2020-03-26-credit-card-fraud-detection/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/26/2020-03-26-credit-card-fraud-detection/</guid>
      <description>ObjectiveOur goal is to train a Neural Network to detect fraudulent credit card transactions in a dataset referring to two days transactions by european cardholders.
Source: https://www.kaggle.com/mlg-ulb/creditcardfraud/data
Datacredit = read.csv(path)The datasets contains transactions made by credit cards in September 2013 by european cardholders.This dataset presents transactions that occurred in two days.
As we can see, this dataset consists of thirty explanatory variables, and a response variable which represents whether a transation was a fraud or not.</description>
    </item>
    
    <item>
      <title>Supervised Learning with Scikit-Learn</title>
      <link>/blog/2020/03/18/2020-03-18-supervised-learning-with-scikit-learn/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/18/2020-03-18-supervised-learning-with-scikit-learn/</guid>
      <description>1. The Iris dataset in scikit-learnfrom sklearn import datasetsimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltplt.style.use(&amp;#39;ggplot&amp;#39;)iris = datasets.load_iris()type(iris)## &amp;lt;class &amp;#39;sklearn.utils.Bunch&amp;#39;&amp;gt;print(iris.keys())## dict_keys([&amp;#39;data&amp;#39;, &amp;#39;target&amp;#39;, &amp;#39;target_names&amp;#39;, &amp;#39;DESCR&amp;#39;, &amp;#39;feature_names&amp;#39;, &amp;#39;filename&amp;#39;])print(iris.DESCR)## .. _iris_dataset:## ## Iris plants dataset## --------------------## ## **Data Set Characteristics:**## ## :Number of Instances: 150 (50 in each of three classes)## :Number of Attributes: 4 numeric, predictive attributes and the class## :Attribute Information:## - sepal length in cm## - sepal width in cm## - petal length in cm## - petal width in cm## - class:## - Iris-Setosa## - Iris-Versicolour## - Iris-Virginica## ## :Summary Statistics:## ## ============== ==== ==== ======= ===== ====================## Min Max Mean SD Class Correlation## ============== ==== ==== ======= ===== ====================## sepal length: 4.</description>
    </item>
    
    <item>
      <title>Linear Models - Scikit Learn</title>
      <link>/blog/2020/03/14/2020-03-14-linear-models-scikit-learn/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/14/2020-03-14-linear-models-scikit-learn/</guid>
      <description>1. Linear ModelsThe target value is expected to be a linear combination of the features.
1.1. Ordinary Least Squares (OLS)The OLS is a optimization math technique that aim to find the better adjustment for a set data and try to minimize the residual sum of squares between the observed targets in the dataset and the targets predicted by the linear approximation.
from sklearn import linear_modelreg = linear_model.</description>
    </item>
    
    <item>
      <title>TensorFlow 2 - Quickstart for Beginners</title>
      <link>/blog/2020/03/14/2020-03-14-tensorflow-2-quickstart-for-beginners/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/14/2020-03-14-tensorflow-2-quickstart-for-beginners/</guid>
      <description>from __future__ import absolute_import, division, print_function, unicode_literalsimport tensorflow as tfmnist = tf.keras.datasets.mnist(x_train, y_train), (x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),tf.keras.layers.Dense(128, activation=&amp;#39;relu&amp;#39;),tf.keras.layers.Dropout(0.2),tf.keras.layers.Dense(10)])predictions = model(x_train[:1]).numpy()## WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer&amp;#39;s dtype of float32, which is new behavior in TensorFlow 2.</description>
    </item>
    
  </channel>
</rss>