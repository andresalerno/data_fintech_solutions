<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on DFS</title>
    <link>/categories/python/</link>
    <description>Recent content in Python on DFS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 21 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Intermediate Importing Data in Python</title>
      <link>/blog/2020/03/21/2020-03-21-intermediate-importing-data-in-python/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/21/2020-03-21-intermediate-importing-data-in-python/</guid>
      <description>1. Importing flat files from the web: your turn!# Import packagefrom urllib.request import urlretrieve# Import pandasimport pandas as pd# Assign url of file: urlurl = &amp;#39;https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&amp;#39;# Save file locallyurlretrieve(url, &amp;#39;winequality-red.csv&amp;#39;)# Read file into a DataFrame and print its head## (&amp;#39;winequality-red.csv&amp;#39;, &amp;lt;http.client.HTTPMessage object at 0x000000001FBF52C8&amp;gt;)df = pd.read_csv(&amp;#39;winequality-red.csv&amp;#39;, sep=&amp;#39;;&amp;#39;)print(df.head())## fixed acidity volatile acidity citric acid ... sulphates alcohol quality## 0 7.</description>
    </item>
    
    <item>
      <title>Introduction to Importing Data in Python</title>
      <link>/blog/2020/03/19/2020-03-19-introduction-to-importing-data-in-python/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/19/2020-03-19-introduction-to-importing-data-in-python/</guid>
      <description>1. Importing entire text files# Open a file: filefile = open(&amp;#39;c:/blogdown/moby_dick.txt&amp;#39;, mode=&amp;#39;r&amp;#39;)# Print itprint(file.read())# Check whether file is closed## CHAPTER 1. Loomings.## ## Call me Ishmael. Some years ago--never mind how long precisely--having## little or no money in my purse, and nothing particular to interest me on## shore, I thought I would sail about a little and see the watery part of## the world.</description>
    </item>
    
    <item>
      <title>Supervised Learning with Scikit-Learn</title>
      <link>/blog/2020/03/18/2020-03-18-supervised-learning-with-scikit-learn/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/18/2020-03-18-supervised-learning-with-scikit-learn/</guid>
      <description>1. The Iris dataset in scikit-learnfrom sklearn import datasetsimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltplt.style.use(&amp;#39;ggplot&amp;#39;)iris = datasets.load_iris()type(iris)## &amp;lt;class &amp;#39;sklearn.utils.Bunch&amp;#39;&amp;gt;print(iris.keys())## dict_keys([&amp;#39;data&amp;#39;, &amp;#39;target&amp;#39;, &amp;#39;target_names&amp;#39;, &amp;#39;DESCR&amp;#39;, &amp;#39;feature_names&amp;#39;, &amp;#39;filename&amp;#39;])print(iris.DESCR)## .. _iris_dataset:## ## Iris plants dataset## --------------------## ## **Data Set Characteristics:**## ## :Number of Instances: 150 (50 in each of three classes)## :Number of Attributes: 4 numeric, predictive attributes and the class## :Attribute Information:## - sepal length in cm## - sepal width in cm## - petal length in cm## - petal width in cm## - class:## - Iris-Setosa## - Iris-Versicolour## - Iris-Virginica## ## :Summary Statistics:## ## ============== ==== ==== ======= ===== ====================## Min Max Mean SD Class Correlation## ============== ==== ==== ======= ===== ====================## sepal length: 4.</description>
    </item>
    
    <item>
      <title>Python Data Science - part 1</title>
      <link>/blog/2020/03/15/2020-03-15-python-data-science-part-1/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/15/2020-03-15-python-data-science-part-1/</guid>
      <description>1. Single Parameter Function# Define shout with the parameter, worddef shout(word):&amp;quot;&amp;quot;&amp;quot;Print a string with three exclamation marks&amp;quot;&amp;quot;&amp;quot;# Concatenate the strings: shout_wordshout_word = word + &amp;#39;!!!&amp;#39;# Print shout_wordprint(shout_word)# Call shout with the string &amp;#39;congratulations&amp;#39;shout(&amp;quot;Congratulations&amp;quot;)## Congratulations!!!2. Functions that return single values# Define shout with the parameter, worddef shout(word):&amp;quot;&amp;quot;&amp;quot;Return a string with three exclamation marks&amp;quot;&amp;quot;&amp;quot;# Concatenate the strings: shout_wordshout_word = word + &amp;quot;!</description>
    </item>
    
    <item>
      <title>Linear Models - Scikit Learn</title>
      <link>/blog/2020/03/14/2020-03-14-linear-models-scikit-learn/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/14/2020-03-14-linear-models-scikit-learn/</guid>
      <description>1. Linear ModelsThe target value is expected to be a linear combination of the features.
1.1. Ordinary Least Squares (OLS)The OLS is a optimization math technique that aim to find the better adjustment for a set data and try to minimize the residual sum of squares between the observed targets in the dataset and the targets predicted by the linear approximation.
from sklearn import linear_modelreg = linear_model.</description>
    </item>
    
    <item>
      <title>TensorFlow 2 - Quickstart for Beginners</title>
      <link>/blog/2020/03/14/2020-03-14-tensorflow-2-quickstart-for-beginners/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/14/2020-03-14-tensorflow-2-quickstart-for-beginners/</guid>
      <description>from __future__ import absolute_import, division, print_function, unicode_literalsimport tensorflow as tfmnist = tf.keras.datasets.mnist(x_train, y_train), (x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),tf.keras.layers.Dense(128, activation=&amp;#39;relu&amp;#39;),tf.keras.layers.Dropout(0.2),tf.keras.layers.Dense(10)])predictions = model(x_train[:1]).numpy()## WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer&amp;#39;s dtype of float32, which is new behavior in TensorFlow 2.</description>
    </item>
    
    <item>
      <title>Iterables versus Iterators</title>
      <link>/blog/2020/03/09/2020-03-09-iterables-versus-iterators/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/03/09/2020-03-09-iterables-versus-iterators/</guid>
      <description>1. Defining a listflash1 = [&amp;#39;jay garrick&amp;#39;, &amp;#39;barry allen&amp;#39;, &amp;#39;wally west&amp;#39;, &amp;#39;bart allen&amp;#39;]a = 1</description>
    </item>
    
    <item>
      <title>A Game of Chance</title>
      <link>/blog/2020/02/29/2020-02-29-a-game-of-chance/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/02/29/2020-02-29-a-game-of-chance/</guid>
      <description>&amp;quot;&amp;quot;&amp;quot;Simulating the dice game Craps&amp;quot;&amp;quot;&amp;quot;## &amp;#39;Simulating the dice game Craps&amp;#39;import randomdef roll_dice():&amp;quot;&amp;quot;&amp;quot;Roll two dice and return their face values as a tuple.&amp;quot;&amp;quot;&amp;quot;die1 = random.randrange(1,7)die2 = random.randrange(1,7)return (die1, die2)def display_dice(dice):&amp;quot;&amp;quot;&amp;quot;Display one roll of the two dice.&amp;quot;&amp;quot;&amp;quot;die1, die2 = diceprint(f&amp;#39;Player rolled {die1} + {die2} = {sum(dice)}&amp;#39;)die_values = roll_dice() #first rolldisplay_dice(die_values)# determine game status and point, based on first roll.</description>
    </item>
    
    <item>
      <title>Functions</title>
      <link>/blog/2020/02/29/2020-03-01-functions/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/2020/02/29/2020-03-01-functions/</guid>
      <description>1. Defining functionsdef square(number):print(&amp;quot;The square of&amp;quot;, number, &amp;quot;is&amp;quot;, number ** 2)square(7)## The square of 7 is 492. Functions with multiple parametersdef maximum(value1, value2, value3):max_value = value1if value2 &amp;gt; max_value:max_value = value2if value3 &amp;gt; max_value:max_value = value3return max_valuemaximum(12, 27, 36)## 36maximum(&amp;#39;yellow&amp;#39;, &amp;#39;red&amp;#39;, &amp;#39;orange&amp;#39;)## &amp;#39;yellow&amp;#39;3. Random-Number Generationimport randomrandom.</description>
    </item>
    
    <item>
      <title>Binary Search Algorithm</title>
      <link>/blog/2019/12/28/2019-12-28-binary-search/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/12/28/2019-12-28-binary-search/</guid>
      <description>def binary_search(lista, item):low = 0 # low and high are part of the list thar you are searching forhigh = len(lista) - 1while low &amp;lt;= high: #while you are not achieving one unique elementmiddle = (low + high) // 2 # checking the central elementguess = lista[middle]if guess == item:return middleif guess &amp;gt; item: # the guess are too highhigh = middle - 1else: # the guess are too lowlow = middle + 1return Nonemy_list = [1, 3, 5, 7, 9]print(binary_search(my_list, 3))## 1print(binary_search(my_list, -1))## None</description>
    </item>
    
    <item>
      <title>Quicksort Algorithm</title>
      <link>/blog/2019/12/26/2019-12-27-quicksort-algorithm/</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/12/26/2019-12-27-quicksort-algorithm/</guid>
      <description>def quicksort(array):if len(array) &amp;lt; 2:return arrayelse:pivo = array[0] # caso recursivomenores = [i for i in array [1:] if i &amp;lt;= pivo] # subarray de todos os elementos menores do que o pivomaiores = [i for i in array[1:] if i &amp;gt; pivo] # subarray de todos os elementos maiores do que o pivoreturn quicksort(menores) + [pivo] + quicksort(maiores)print(quicksort([10, 5, 2, 3]))## [2, 3, 5, 10]</description>
    </item>
    
  </channel>
</rss>